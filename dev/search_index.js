var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = GraduatedNonConvexity","category":"page"},{"location":"#GraduatedNonConvexity","page":"Home","title":"GraduatedNonConvexity","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for GraduatedNonConvexity.","category":"page"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This library is built to solve optimization problems of the form","category":"page"},{"location":"","page":"Home","title":"Home","text":"min_x sum_i=1^N rho_mu ( r ( y_i x) )","category":"page"},{"location":"","page":"Home","title":"Home","text":"where rho_mu is the surrogate of a (non-convex) robust cost function rho. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"To do this, it instead solves two problems repeatedly in a loop:","category":"page"},{"location":"","page":"Home","title":"Home","text":"x^k+1 gets operatornameargmin_x sum_i=1^N w_i^k r^2(y_i x)","category":"page"},{"location":"","page":"Home","title":"Home","text":"w^k+1 gets operatornameargmin_w sum_i=1^N w_i r^2(y_i x^k+1) + Phi_rho(w_i)","category":"page"},{"location":"","page":"Home","title":"Home","text":"i.e., it solves the non-convex robust optimization as a sequence of weighted least-squares problems. This method is particulary good when step 1 has a closed-form solution or a good solver, and step 2 has analytic solutions. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"This library assumes you have a function LSQ_fn that can perform the optimization in step 1. Then, it performs step 2 analytically, for some specific robust cost functions. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The supported robust cost functions are:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Geman McClure:","category":"page"},{"location":"","page":"Home","title":"Home","text":"rho(r) = fracbarc^2 r^2barc^2  + r^2","category":"page"},{"location":"","page":"Home","title":"Home","text":"Truncated Least Squares:","category":"page"},{"location":"","page":"Home","title":"Home","text":"rho(r) = begincases\nr^2  textif  r^2 in 0 barc^2\nbarc^2  textif  r^2 in barc^2 infty)\nendcases","category":"page"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"See the example below on how to use the library:","category":"page"},{"location":"","page":"Home","title":"Home","text":"First, we construct the data","category":"page"},{"location":"","page":"Home","title":"Home","text":"using LinearAlgebra\n\n## construct dataset\nN=1000\n\n# this is the ground truth parameter we are trying to solve for\nβ_gt = randn(2)\n\nx = randn(N, 2)\nx[:,2] .= 1\n\n# create some noise-free measurements\ny = x * β_gt\n\n# add some outliers to 2% of data\nfor i=1:N\n    rand() < 0.02 ? y[i] += 1.0 + rand()  : continue\nend\n\n# collect all the necessary data\ndata = (x, y)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Next, we define the weighted least squares solver, and the residual calculation functions","category":"page"},{"location":"","page":"Home","title":"Home","text":"## define weighted least squares solver\nfunction least_sq_solver(w, data)\n    \n    X = data[1]\n    y = data[2]\n    \n    W = diagm(w)\n\n    # analytic expression for weighted least squares\n    return (X' * W * X) \\ (X' * W * y)\nend\n\n## define residual function\nfunction residual_fn(β, data)\n  X = data[1]\n  y = data[2]\n  return y - X * β\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"And now solve:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using GraduatedNonConvexity\n\n# define maximum residual of inliers\nc = 0.3\n\n## Solve using GNC\nβ_gm = GNC_GM(N, data, least_sq_solver, residual_fn, c; verbose=false) # or\nβ_tls = GNC_TLS(N, data, least_sq_solver, residual_fn, c; verbose=false)","category":"page"},{"location":"","page":"Home","title":"Home","text":"To save allocations, you can also provide in-place versions of the least squares solvers and the residual functions:","category":"page"},{"location":"","page":"Home","title":"Home","text":"function least_sq_solver!(x, w, data)\n    ...\nend \n\nfunction residual_fn!(res, β, data)\n    ...\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"and you can call the library in place:","category":"page"},{"location":"","page":"Home","title":"Home","text":"β_gnc = zeros(2) # provide the initial guess for the solution\nGNC_GM!(β_gnc, N, data, least_sq_solver!, residual_fn!, c; verbose=false) # or\nGNC_TLS!(β_gnc, N, data, least_sq_solver!, residual_fn!, c; verbose=false)","category":"page"},{"location":"#References","page":"Home","title":"References","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"See the following paper for details on the method and implementation:","category":"page"},{"location":"","page":"Home","title":"Home","text":"H. Yang, P. Antonante, V. Tzoumas, and L. Carlone,\n“Graduated Non-Convexity for Robust Spatial Perception: \nFrom Non-Minimal Solvers to Global Outlier Rejection”,\nIEEE Robotics and Automation Letters (RA-L), 2020.","category":"page"},{"location":"#Documentation","page":"Home","title":"Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [GraduatedNonConvexity]","category":"page"},{"location":"#GraduatedNonConvexity.GNC_GM!-NTuple{6, Any}","page":"Home","title":"GraduatedNonConvexity.GNC_GM!","text":"GNC_GM!(x, N, data, LSQ_fn!, RES_fn!, c)\n\nIn-place version of GNC_GM\n\nInputs:\n\nx: starting point for the robust least squares\nN: the number of data points (equal to the number of residuals)\ndata: the data which is to be fit\nLSQ_fn!: Assumes LSQ_fn!(x, w, data) updates x in-place with the weighted least squares solution using weights w\nRES_fn!: Assumes RES_fn!(rs, x, data) updates rs in-place with the returns residuals given the candidate solution x. \nc: the maximum residual of an inlier\n\nParameters:\n\n(same as GNC_GM)\n\n\n\n\n\n","category":"method"},{"location":"#GraduatedNonConvexity.GNC_GM-NTuple{5, Any}","page":"Home","title":"GraduatedNonConvexity.GNC_GM","text":"GNC_GM(N, data, LSQ_fn, RES_fn, c)\n\nPerform robust least squares given data using the German-McClure cost function. \n\nInputs:\n\nN: the number of data points (equal to the number of residuals)\ndata: the data which is to be fit\nLSQ_fn: Assumes LSQ_fn(w, data) returns the weighted least squares solution using the weights w\nRES_fn: Assumes RES_fn(x, data) returns a vector with the residuals given the candidate solution x. \nc: the maximum residual of an inlier\n\nParameters:\n\nmax_iterations=1000\nμ_factor=1.4: factor to decrease μ by each iteration.\nverbose=true\nrtol=1e-6\n\nTerminates when rtol is reached, or μ=1.\n\n\n\n\n\n","category":"method"},{"location":"#GraduatedNonConvexity.GNC_TLS!-NTuple{6, Any}","page":"Home","title":"GraduatedNonConvexity.GNC_TLS!","text":"GNC_TLS!(x, N, data, LSQ_fn!, RES_fn!, c)\n\nIn-place version of GNC_TLS\n\nInputs:\n\nx: starting point for the robust least squares\nN: the number of data points (equal to the number of residuals)\ndata: the data which is to be fit\nLSQ_fn!: Assumes LSQ_fn!(x, w, data) updates x in-place with the weighted least squares solution using weights w\nRES_fn!: Assumes RES_fn!(rs, x, data) updates rs in-place with the returns residuals given the candidate solution x. \nc: the maximum residual of an inlier\n\nParameters:\n\n(same as GNC_TLS)\n\n\n\n\n\n","category":"method"},{"location":"#GraduatedNonConvexity.GNC_TLS-NTuple{5, Any}","page":"Home","title":"GraduatedNonConvexity.GNC_TLS","text":"GNC_TLS(N, data, LSQ_fn, RES_fn, c)\n\nPerform robust least squares given data using the Truncated Least Squares cost function. \n\nInputs:\n\nN: the number of data points (equal to the number of residuals)\ndata: the data which is to be fit\nLSQ_fn: Assumes LSQ_fn(w, data) returns the weighted least squares solution using the weights w\nRES_fn: Assumes RES_fn(x, data) returns a vector with the residuals given the candidate solution x. \nc: the maximum residual of an inlier\n\nParameters:\n\nmax_iterations=1000\nμ_factor=1.4: factor to increase μ by each iteration.\nverbose=true\nrtol=1e-6\n\nTerminates when rtol is reached.\n\n\n\n\n\n","category":"method"}]
}
